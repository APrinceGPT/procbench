"""
ProcBench Malware Hunter
- Parent-Child Process Tree Analysis
- AI-Powered Legitimacy Assessment
- Behavioral Tagging with Reasoning
"""

from procmon_parser import ProcmonLogsReader
from collections import defaultdict, Counter
from datetime import datetime
from openai import OpenAI
import json
import os

class MalwareHunter:
    def __init__(self, pml_path: str):
        self.pml_path = pml_path
        self.events = []
        self.processes = {}
        self.process_tree = defaultdict(list)  # parent -> [children]
        self.process_behaviors = defaultdict(list)
        self.ai_assessments = {}
        
        # Initialize AI client
        self.client = OpenAI(
            base_url="https://api.rdsec.trendmicro.com/prod/aiendpoint/v1/",
            api_key="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJuYW1lIjoiQUktMTc2ODg1MDExODA4NiIsInJvbGVzIjpbIjM1Il0sInVzZXJfaWQiOjI1MjQsInVzZXJuYW1lIjoiYWRyaWFucCIsInJvbGVfbmFtZXMiOlsiUk9QLWFpZW5kcG9pbnQtVXNlciJdLCJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzc2NjI2MTE4LCJqdGkiOiIzMTMyZjkwZS1mNTZiLTExZjAtYmRkYS1kZWVkMmM5MmVhNjUiLCJ2ZXJzaW9uIjoiMjAyNC0xMS0wMSJ9.K40DWcyjyk0azAfJwVi-l4bCaFhryvecdQx57DVWEpw"
        )
        
    def parse_pml(self):
        """Parse PML and build process relationships"""
        print("[*] Parsing PML file and building process tree...")
        
        with open(self.pml_path, "rb") as f:
            reader = ProcmonLogsReader(f)
            
            for i, event in enumerate(reader):
                # Extract process info
                proc_str = str(event.process)
                if '"' in proc_str:
                    parts = proc_str.split('"')
                    proc_path = parts[1] if len(parts) > 1 else "unknown"
                    proc_name = proc_path.split('\\')[-1]
                    pid = parts[2].strip(', ') if len(parts) > 2 else "0"
                else:
                    proc_path = "unknown"
                    proc_name = "unknown" 
                    pid = "0"
                
                proc_key = f"{proc_name}|{pid}"
                
                # Track process info
                if proc_key not in self.processes:
                    self.processes[proc_key] = {
                        'name': proc_name,
                        'path': proc_path,
                        'pid': pid,
                        'operations': Counter(),
                        'files_accessed': [],
                        'registry_accessed': [],
                        'network_activity': [],
                        'child_processes': [],
                        'first_seen': event.date_filetime,
                        'last_seen': event.date_filetime,
                        'event_count': 0
                    }
                
                proc = self.processes[proc_key]
                proc['operations'][event.operation] += 1
                proc['last_seen'] = event.date_filetime
                proc['event_count'] += 1
                
                # Categorize behaviors
                op = event.operation
                path = event.path or ""
                
                # File operations
                if 'File' in str(event.event_class) or op in ['CreateFile', 'WriteFile', 'ReadFile', 'DeleteFile']:
                    if path and len(proc['files_accessed']) < 100:
                        proc['files_accessed'].append({
                            'operation': op,
                            'path': path,
                            'result': str(event.result)
                        })
                
                # Registry operations
                if 'Reg' in op:
                    if path and len(proc['registry_accessed']) < 100:
                        proc['registry_accessed'].append({
                            'operation': op,
                            'key': path,
                            'result': str(event.result)
                        })
                
                # Process creation (parent-child relationship)
                if op == 'Process Create' or op == 'Process Start':
                    if path:
                        child_name = path.split('\\')[-1]
                        proc['child_processes'].append(child_name)
                        self.process_tree[proc_name].append(child_name)
                
                if i % 10000 == 0 and i > 0:
                    print(f"  Processed {i:,} events...")
        
        print(f"[+] Parsed {len(self.processes)} unique process instances")
        return self
    
    def analyze_with_ai(self, batch_size=10):
        """Use AI to assess legitimacy of each process"""
        print("[*] Running AI-powered legitimacy assessment...")
        
        # Group processes by name for efficiency
        unique_processes = {}
        for proc_key, data in self.processes.items():
            name = data['name']
            if name not in unique_processes:
                unique_processes[name] = data
            else:
                # Merge data
                unique_processes[name]['event_count'] += data['event_count']
                unique_processes[name]['files_accessed'].extend(data['files_accessed'][:20])
                unique_processes[name]['registry_accessed'].extend(data['registry_accessed'][:20])
        
        print(f"[*] Analyzing {len(unique_processes)} unique processes with AI...")
        
        # Prepare process summaries for AI
        process_summaries = []
        for name, data in unique_processes.items():
            summary = {
                'name': name,
                'path': data['path'],
                'event_count': data['event_count'],
                'top_operations': dict(data['operations'].most_common(5)),
                'sample_files': [f['path'] for f in data['files_accessed'][:5]],
                'sample_registry': [r['key'] for r in data['registry_accessed'][:5]],
                'spawned_processes': list(set(data['child_processes']))[:5]
            }
            process_summaries.append(summary)
        
        # Analyze in batches
        all_assessments = []
        for i in range(0, len(process_summaries), batch_size):
            batch = process_summaries[i:i+batch_size]
            print(f"  Analyzing batch {i//batch_size + 1}/{(len(process_summaries)-1)//batch_size + 1}...")
            
            prompt = f"""You are a malware analyst examining Process Monitor data from a potentially infected system.

Analyze each process below and provide:
1. LEGITIMACY: Is this process legitimate or suspicious? (LEGITIMATE / SUSPICIOUS / MALICIOUS / UNKNOWN)
2. REASONING: Why do you think so? (1-2 sentences)
3. BEHAVIOR_TAGS: List concerning behaviors if any (e.g., "persistence", "data_exfiltration", "process_injection", "lateral_movement", "credential_access")
4. RISK_SCORE: 0-100 (0=safe, 100=definitely malware)

Consider:
- Is the executable path normal for this process?
- Are the operations typical for this process?
- Are there suspicious parent-child relationships?
- Is it accessing sensitive files/registry keys?

PROCESSES TO ANALYZE:
{json.dumps(batch, indent=2)}

Respond in JSON format:
{{
  "assessments": [
    {{
      "process_name": "example.exe",
      "legitimacy": "LEGITIMATE|SUSPICIOUS|MALICIOUS|UNKNOWN",
      "reasoning": "explanation here",
      "behavior_tags": ["tag1", "tag2"],
      "risk_score": 0-100
    }}
  ]
}}"""

            try:
                response = self.client.chat.completions.create(
                    model="claude-4-sonnet",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1
                )
                
                result_text = response.choices[0].message.content
                
                # Parse JSON from response
                try:
                    # Find JSON in response
                    start = result_text.find('{')
                    end = result_text.rfind('}') + 1
                    if start >= 0 and end > start:
                        result = json.loads(result_text[start:end])
                        all_assessments.extend(result.get('assessments', []))
                except json.JSONDecodeError:
                    print(f"    Warning: Could not parse AI response for batch")
                    
            except Exception as e:
                print(f"    Error calling AI: {e}")
        
        # Store assessments
        for assessment in all_assessments:
            name = assessment.get('process_name', '')
            self.ai_assessments[name] = assessment
        
        print(f"[+] AI assessed {len(self.ai_assessments)} processes")
        return self
    
    def generate_report(self, output_path="malware_hunt_report.html"):
        """Generate visual report with process tree and AI assessments"""
        print("[*] Generating malware hunting report...")
        
        # Sort processes by risk
        sorted_assessments = sorted(
            self.ai_assessments.items(),
            key=lambda x: x[1].get('risk_score', 0),
            reverse=True
        )
        
        # Build process tree structure for visualization
        tree_data = []
        root_processes = set(self.process_tree.keys())
        all_children = set()
        for children in self.process_tree.values():
            all_children.update(children)
        root_only = root_processes - all_children
        
        # Count by legitimacy
        legitimacy_counts = Counter(a.get('legitimacy', 'UNKNOWN') for _, a in sorted_assessments)
        high_risk = [a for _, a in sorted_assessments if a.get('risk_score', 0) >= 70]
        medium_risk = [a for _, a in sorted_assessments if 30 <= a.get('risk_score', 0) < 70]
        
        html = f'''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>ProcBench - Malware Hunt Report</title>
    <style>
        :root {{
            --bg-dark: #0a0a0f;
            --bg-card: #12121a;
            --bg-card-hover: #1a1a25;
            --text: #e0e0e0;
            --text-dim: #888;
            --red: #ff4757;
            --orange: #ffa502;
            --yellow: #ffdd59;
            --green: #2ed573;
            --blue: #3498db;
            --purple: #9b59b6;
            --border: #2a2a3a;
        }}
        
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ 
            font-family: 'Segoe UI', system-ui, sans-serif;
            background: var(--bg-dark);
            color: var(--text);
            line-height: 1.5;
        }}
        
        .container {{ max-width: 1600px; margin: 0 auto; padding: 24px; }}
        
        /* Header */
        .header {{
            background: linear-gradient(135deg, #1a1a2e, #0f0f1a);
            border: 1px solid var(--border);
            border-radius: 16px;
            padding: 32px;
            margin-bottom: 24px;
        }}
        
        .header h1 {{
            font-size: 32px;
            margin-bottom: 8px;
            background: linear-gradient(90deg, var(--red), var(--orange));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }}
        
        /* Summary Cards */
        .summary-grid {{
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 16px;
            margin-bottom: 24px;
        }}
        
        .summary-card {{
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 24px;
            text-align: center;
        }}
        
        .summary-card .number {{
            font-size: 48px;
            font-weight: bold;
        }}
        
        .summary-card .label {{ color: var(--text-dim); }}
        .summary-card.malicious .number {{ color: var(--red); }}
        .summary-card.suspicious .number {{ color: var(--orange); }}
        .summary-card.legitimate .number {{ color: var(--green); }}
        
        /* Process Tree Section */
        .section {{
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            margin-bottom: 24px;
            overflow: hidden;
        }}
        
        .section-header {{
            background: #1a1a25;
            padding: 16px 24px;
            font-size: 18px;
            font-weight: 600;
            border-bottom: 1px solid var(--border);
        }}
        
        .section-content {{ padding: 24px; }}
        
        /* Process Tree Visualization */
        .process-tree {{
            font-family: 'Consolas', monospace;
            font-size: 14px;
        }}
        
        .tree-node {{
            padding: 8px 12px;
            margin: 4px 0;
            border-radius: 6px;
            display: flex;
            align-items: center;
            gap: 12px;
            cursor: pointer;
            transition: background 0.2s;
        }}
        
        .tree-node:hover {{ background: var(--bg-card-hover); }}
        
        .tree-node.malicious {{ 
            background: rgba(255, 71, 87, 0.15);
            border-left: 3px solid var(--red);
        }}
        
        .tree-node.suspicious {{ 
            background: rgba(255, 165, 2, 0.15);
            border-left: 3px solid var(--orange);
        }}
        
        .tree-node.legitimate {{
            border-left: 3px solid var(--green);
        }}
        
        .tree-children {{
            margin-left: 32px;
            border-left: 2px dashed var(--border);
            padding-left: 16px;
        }}
        
        .risk-badge {{
            padding: 2px 8px;
            border-radius: 10px;
            font-size: 11px;
            font-weight: 600;
        }}
        
        .risk-badge.high {{ background: var(--red); color: white; }}
        .risk-badge.medium {{ background: var(--orange); color: black; }}
        .risk-badge.low {{ background: var(--green); color: black; }}
        
        /* Behavior Tags */
        .behavior-tag {{
            display: inline-block;
            padding: 2px 8px;
            margin: 2px;
            border-radius: 4px;
            font-size: 11px;
            background: rgba(155, 89, 182, 0.3);
            color: var(--purple);
        }}
        
        .behavior-tag.persistence {{ background: rgba(255, 71, 87, 0.3); color: var(--red); }}
        .behavior-tag.data_exfiltration {{ background: rgba(255, 71, 87, 0.3); color: var(--red); }}
        .behavior-tag.process_injection {{ background: rgba(255, 71, 87, 0.3); color: var(--red); }}
        .behavior-tag.credential_access {{ background: rgba(255, 165, 2, 0.3); color: var(--orange); }}
        
        /* Process Details Panel */
        .process-card {{
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 20px;
            margin-bottom: 16px;
        }}
        
        .process-card.malicious {{ border-color: var(--red); }}
        .process-card.suspicious {{ border-color: var(--orange); }}
        
        .process-header {{
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 12px;
        }}
        
        .process-name {{
            font-size: 18px;
            font-weight: 600;
            font-family: 'Consolas', monospace;
        }}
        
        .process-path {{
            font-size: 12px;
            color: var(--text-dim);
            word-break: break-all;
            margin-bottom: 12px;
        }}
        
        .ai-reasoning {{
            background: rgba(52, 152, 219, 0.1);
            border-left: 3px solid var(--blue);
            padding: 12px;
            margin: 12px 0;
            font-size: 14px;
        }}
        
        .ai-reasoning strong {{ color: var(--blue); }}
        
        /* Legend */
        .legend {{
            display: flex;
            gap: 24px;
            padding: 16px;
            background: var(--bg-card);
            border-radius: 8px;
            margin-bottom: 24px;
            flex-wrap: wrap;
        }}
        
        .legend-item {{
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 14px;
        }}
        
        .legend-color {{
            width: 16px;
            height: 16px;
            border-radius: 4px;
        }}
        
        @media (max-width: 900px) {{
            .summary-grid {{ grid-template-columns: repeat(2, 1fr); }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üîç ProcBench Malware Hunt Report</h1>
            <p style="color: var(--text-dim);">AI-Powered Process Analysis | {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <!-- Summary -->
        <div class="summary-grid">
            <div class="summary-card malicious">
                <div class="number">{len(high_risk)}</div>
                <div class="label">High Risk</div>
            </div>
            <div class="summary-card suspicious">
                <div class="number">{len(medium_risk)}</div>
                <div class="label">Medium Risk</div>
            </div>
            <div class="summary-card legitimate">
                <div class="number">{legitimacy_counts.get('LEGITIMATE', 0)}</div>
                <div class="label">Legitimate</div>
            </div>
            <div class="summary-card">
                <div class="number">{len(self.processes)}</div>
                <div class="label">Total Processes</div>
            </div>
        </div>
        
        <!-- Legend -->
        <div class="legend">
            <div class="legend-item">
                <div class="legend-color" style="background: var(--red);"></div>
                <span>Malicious / High Risk</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: var(--orange);"></div>
                <span>Suspicious / Medium Risk</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: var(--green);"></div>
                <span>Legitimate / Low Risk</span>
            </div>
            <div class="legend-item">
                <div class="legend-color" style="background: var(--purple);"></div>
                <span>Behavior Tag</span>
            </div>
        </div>
        
        <!-- High Risk Processes - Detailed -->
        <div class="section">
            <div class="section-header" style="background: rgba(255,71,87,0.2);">
                üö® High Risk Processes - AI Assessment
            </div>
            <div class="section-content">
                {self._generate_process_cards([a for a in sorted_assessments if a[1].get('risk_score', 0) >= 50][:20])}
            </div>
        </div>
        
        <!-- Process Tree -->
        <div class="section">
            <div class="section-header">
                üå≥ Parent-Child Process Tree
            </div>
            <div class="section-content">
                <div class="process-tree">
                    {self._generate_tree_html()}
                </div>
            </div>
        </div>
        
        <!-- All Process Assessments -->
        <div class="section">
            <div class="section-header">
                üìã All Process Legitimacy Assessments
            </div>
            <div class="section-content">
                <table style="width: 100%; border-collapse: collapse;">
                    <thead>
                        <tr style="text-align: left; border-bottom: 2px solid var(--border);">
                            <th style="padding: 12px;">Process</th>
                            <th style="padding: 12px;">Legitimacy</th>
                            <th style="padding: 12px;">Risk</th>
                            <th style="padding: 12px;">Behavior Tags</th>
                            <th style="padding: 12px;">AI Reasoning</th>
                        </tr>
                    </thead>
                    <tbody>
                        {self._generate_table_rows(sorted_assessments)}
                    </tbody>
                </table>
            </div>
        </div>
    </div>
</body>
</html>'''
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)
        
        print(f"[+] Report saved to: {output_path}")
        return output_path
    
    def _generate_process_cards(self, assessments):
        """Generate detailed process cards for high-risk processes"""
        cards = []
        for name, data in assessments:
            proc_data = None
            for pkey, pdata in self.processes.items():
                if pdata['name'] == name:
                    proc_data = pdata
                    break
            
            legitimacy = data.get('legitimacy', 'UNKNOWN').lower()
            risk = data.get('risk_score', 0)
            risk_class = 'high' if risk >= 70 else 'medium' if risk >= 30 else 'low'
            
            tags_html = ''.join(
                f'<span class="behavior-tag {tag.replace(" ", "_")}">{tag}</span>'
                for tag in data.get('behavior_tags', [])
            )
            
            children = self.process_tree.get(name, [])
            children_html = f"<p><strong>Spawned Processes:</strong> {', '.join(children[:5])}</p>" if children else ""
            
            files = proc_data.get('files_accessed', [])[:5] if proc_data else []
            files_html = "<p><strong>Files Accessed:</strong></p><ul>" + "".join(
                f"<li style='font-size:12px; color: var(--text-dim);'>{f['operation']}: {f['path'][:60]}...</li>"
                for f in files
            ) + "</ul>" if files else ""
            
            cards.append(f'''
            <div class="process-card {legitimacy}">
                <div class="process-header">
                    <div>
                        <div class="process-name">{name}</div>
                        <div class="process-path">{proc_data['path'] if proc_data else 'Unknown path'}</div>
                    </div>
                    <div>
                        <span class="risk-badge {risk_class}">Risk: {risk}</span>
                    </div>
                </div>
                
                <div style="margin-bottom: 8px;">
                    {tags_html if tags_html else '<span style="color: var(--text-dim);">No concerning behaviors tagged</span>'}
                </div>
                
                <div class="ai-reasoning">
                    <strong>ü§ñ AI Analysis:</strong> {data.get('reasoning', 'No analysis available')}
                </div>
                
                {children_html}
                {files_html}
            </div>
            ''')
        
        return ''.join(cards) if cards else '<p style="color: var(--text-dim);">No high-risk processes detected</p>'
    
    def _generate_tree_html(self):
        """Generate process tree HTML"""
        # Find root processes (those that spawned others but weren't spawned)
        all_children = set()
        for children in self.process_tree.values():
            all_children.update(children)
        
        roots = set(self.process_tree.keys()) - all_children
        
        def render_node(name, depth=0):
            assessment = self.ai_assessments.get(name, {})
            legitimacy = assessment.get('legitimacy', 'UNKNOWN').lower()
            risk = assessment.get('risk_score', 0)
            risk_class = 'high' if risk >= 70 else 'medium' if risk >= 30 else 'low'
            
            children = self.process_tree.get(name, [])
            
            tags = assessment.get('behavior_tags', [])
            tags_html = ''.join(f'<span class="behavior-tag">{t}</span>' for t in tags[:3])
            
            html = f'''
            <div class="tree-node {legitimacy}">
                <span>{"‚îî‚îÄ‚îÄ " if depth > 0 else "‚óè "}</span>
                <span style="font-weight: 600;">{name}</span>
                <span class="risk-badge {risk_class}">{risk}</span>
                {tags_html}
                <span style="color: var(--text-dim); margin-left: auto; font-size: 12px;">
                    {legitimacy.upper()}
                </span>
            </div>
            '''
            
            if children:
                html += '<div class="tree-children">'
                for child in children[:10]:  # Limit children shown
                    html += render_node(child, depth + 1)
                if len(children) > 10:
                    html += f'<div class="tree-node" style="color: var(--text-dim);">... and {len(children) - 10} more</div>'
                html += '</div>'
            
            return html
        
        tree_html = ''
        for root in sorted(roots)[:20]:
            tree_html += render_node(root)
        
        return tree_html if tree_html else '<p style="color: var(--text-dim);">No parent-child relationships detected in captured events</p>'
    
    def _generate_table_rows(self, assessments):
        """Generate table rows for all assessments"""
        rows = []
        for name, data in assessments[:100]:  # Limit to 100
            legitimacy = data.get('legitimacy', 'UNKNOWN')
            risk = data.get('risk_score', 0)
            
            leg_color = {
                'LEGITIMATE': 'var(--green)',
                'SUSPICIOUS': 'var(--orange)',
                'MALICIOUS': 'var(--red)',
                'UNKNOWN': 'var(--text-dim)'
            }.get(legitimacy, 'var(--text-dim)')
            
            tags = data.get('behavior_tags', [])
            tags_html = ''.join(f'<span class="behavior-tag">{t}</span>' for t in tags)
            
            rows.append(f'''
            <tr style="border-bottom: 1px solid var(--border);">
                <td style="padding: 12px; font-family: Consolas, monospace;">{name}</td>
                <td style="padding: 12px; color: {leg_color}; font-weight: 600;">{legitimacy}</td>
                <td style="padding: 12px;">{risk}</td>
                <td style="padding: 12px;">{tags_html or '-'}</td>
                <td style="padding: 12px; font-size: 13px; color: var(--text-dim);">{data.get('reasoning', '-')[:100]}...</td>
            </tr>
            ''')
        
        return ''.join(rows)


def main():
    pml_path = r"F:\AI Project\AI Project\ProcBench\Logfile.PML"
    output_dir = r"F:\AI Project\AI Project\ProcBench\output"
    
    os.makedirs(output_dir, exist_ok=True)
    
    hunter = MalwareHunter(pml_path)
    hunter.parse_pml()
    hunter.analyze_with_ai(batch_size=15)
    hunter.generate_report(os.path.join(output_dir, "malware_hunt_report.html"))
    
    print("\n" + "="*60)
    print("‚úÖ MALWARE HUNT COMPLETE")
    print("="*60)
    print(f"\nOpen: {os.path.join(output_dir, 'malware_hunt_report.html')}")


if __name__ == "__main__":
    main()
